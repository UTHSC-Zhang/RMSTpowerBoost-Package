---
title: "RMSTSS: Sample Size and Power Calculations for RMST-based Clinical Trials"
name: RMSTSS-Main
css: css/Main.css
output:
  rmarkdown::html_vignette:
    toc: true
    fig_caption: true
    code_folding: hide
    df_print: paged
    highlight: tango
    self_contained: true
bibliography: references.bib
biblio-style: apalike
link-citations: yes
vignette: >
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
cache: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
   message = FALSE,
      # eval = FALSE,
   cache = TRUE,
  cache.lazy = FALSE,   # materialize objects now (safer)
  autodep = TRUE,  
   warning = FALSE,
   comment = NA,
   fig.align = 'center',
   fig.width = 7,
   fig.height = 5,
   table.width = "100%",
   table.align = "center",
   collapse = TRUE
)
packages = c("survival", "dplyr", "tidyr", "knitr", "ggplot2", "mgcv", "kableExtra", "bibtex")
lapply(packages, require, character.only = TRUE)

library(RMSTSS)
```

# Introduction

The design and analysis of clinical trials with time-to-event endpoints often rely on the hazard-based model (e.g., the PH model) and use the hazard ratio (HR) as the primary estimand of the treatment effect. However, the HR can be challenging to interpret from both clinical and causal perspectives. Moreover, the key assumption underlying most hazards models - the proportional hazards assumption - is often tenuous or violated in real-world settings.

As an alternative, the **Restricted Mean Survival Time (RMST)** is gaining favor for its straightforward interpretation and robust properties [@royston2013; @uno2014]. The RMST measures the average event-free time up to a pre-specified follow-up point, $L$. This provides a direct and meaningful measure of treatment benefit (e.g., "an average of 3 extra months of survival over 5 years"), which is highly valuable for clinicians and patients.

Modern statistical methods now focus on modeling the RMST directly as a function of baseline covariates, rather than estimating it indirectly from a survival curve or a hazard function. This direct approach, based on foundational work using Inverse Probability of Censoring Weighting (IPCW) [@tian2014], has been extended to handle the complex data structures observed in modern trials, including facility profiling in multi-center studies or other stratification factors [@wang2019; @zhang2024] and covariate-dependent censoring [@wang2018].

However, most software tools for these advanced methods focus on analyzing existing data, not designing new studies. This has left trial statisticians to write custom code for the crucial task of calculating sample size and power.

The `RMSTSS` package is designed to fill this gap. It provides a comprehensive and user-friendly suite of tools for **power and sample size calculations** based on the latest direct RMST methodologies. The package implements several key approaches from the statistical literature:

* **Generalized Linear Models**: The foundational regression model for RMST with IPCW-based estimation [@tian2014].
* **Stratified Models**: Efficient methods for studies with a large number of strata (e.g., clinical centers), including both **additive** [@zhang2024] and **multiplicative** [@wang2019] models.
* **Dependent Censoring Models**: Methods for handling covariate-dependent censoring [@wang2018].
* **Flexible Non-Linear Models**: Bootstrap-based functions using Generalized Additive Models (GAMs) to capture non-linear covariate effects.
* **Analytic vs. Bootstrap Methods**: For most models, the package offers a choice between a fast `analytical` calculation and a robust, simulation-based `boot` method.

This vignette will guide you through the theory and application of each of these function groups.

------------------------------------------------------------------------

# Core Concepts of `RMSTSS` Package {.tabset}

The `RMSTSS` package uses two primary approaches for its calculations: a fast **Analytic Method** and a robust **Bootstrap Method**. All functions for finding sample size then use a common search algorithm. Understanding these three components is key to choosing the right function for your needs.

## The Analytic Method (`.analytical` functions)

The analytical functions are extremely fast because they use a direct mathematical formula to calculate power. This makes them ideal for quickly exploring different scenarios. The process is:

1.  **One-Time Estimation**: The function first analyzes the provided `pilot_data` to estimate two key parameters:
      * The **treatment effect size** (e.g., the difference in RMST or the log-RMST ratio).
      * The **asymptotic variance** of that effect estimator, which measures its uncertainty.
2.  **Power Formula**: It then plugs these fixed estimates into a standard power formula. For a given total sample size `N`, the power is calculated as:
    $$
\text{Power} = \Phi\left( \frac{|\beta_{\text{effect}}|}{\sigma_N} - z_{1-\alpha/2} \right)
    $$
 where:
      * $\Phi$ is the cumulative distribution function (CDF) of the standard normal distribution.
      * $\beta_{\text{effect}}$ is the treatment effect estimated from the pilot data.
      * $\sigma_N = \frac{\sigma_1}{\sqrt{N}}$ is the standard error of the effect for the target sample size `N`, which is scaled from the pilot data's variance.
      * $z_{1-\alpha/2}$ is the critical value from the standard normal distribution (e.g., 1.96 for an alpha of 0.05).

## The Bootstrap Method (`.boot` functions)

The bootstrap functions provide a robust, simulation-based alternative that makes fewer assumptions about the data's distribution. This is a trade-off, as they are much more computationally intensive. The process is:

1.  **Resample**: The function simulates a "future trial" of a given `sample_size` by resampling with replacement from the `pilot_data`.
2.  **Fit Model**: On this new bootstrap sample, it performs the full analysis (e.g., calculating weights or pseudo-observations and fitting the specified model).
3.  **Get P-Value**: It extracts the p-value for the treatment effect from the fitted model.
4.  **Repeat**: This process is repeated thousands of times (`n_sim`).
5.  **Calculate Power**: The final estimated power is the proportion of simulations where the p-value was less than the significance level `alpha`.
    $$
 \text{Power} = \frac{\text{Number of simulations with } p < \alpha}{n_{\text{sim}}}
    $$

## The Sample Size Search Algorithm (`.ss` functions)

All functions ending in `.ss` (for sample size) use the same iterative search algorithm to find the `N` required to achieve a `target_power`:

1.  **Start**: The search begins with a sample size of `n_start`.
2.  **Calculate Power**: It calculates the power for the `current_n` using either the **analytic formula** or a **full bootstrap simulation**.
3.  **Check Condition**:
      * If `calculated_power >= target_power`, the search succeeds and returns `current_n`.
      * If not, it increments the sample size (`current_n = current_n + n_step`) and repeats the process.
4.  **Stopping Rules**: The search terminates if the sample size exceeds `max_n_per_arm` or, for bootstrap methods, if the power fails to improve for a set number of `patience` steps.

## Avaailable Functions: A Quick Guide

The package uses a consistent naming convention to help you select the correct function. The names are combinations of the `[Model Type]`, the `[Goal - power or ss]`, and the `[Method - analytical or boot]`. The table below provides a summary of the available functions for each model.

| Model Type | Analytic Functions | Bootstrap Functions |
| :--- | :--- | :--- |
| **Linear IPCW** | `linear.power.analytical` <br>`linear.ss.analytical` | `linear.power.boot` <br>`linear.ss.boot` |
| **Additive Stratified** | `additive.power.analytical` <br>`additive.ss.analytical` | *Not applicable* |
| **Multiplicative Stratified**| `MS.power.analytical` <br>`MS.ss.analytical` | `MS.power.boot` <br>`MS.ss.boot` |
| **Semiparametric GAM** | *Not applicable* | `GAM.power.boot` <br>`GAM.ss.boot` |
| **Dependent Censoring** | `DC.power.analytical` <br>`DC.ss.analytical` | *Not applicable* |



## Selecting an Appropriate Model

Model selection depends on the assumptions made about the data structure and the design of the study. The following table summarizes recommended modeling strategies under various analytical scenarios:

| Model                         | Key Assumption / Scenario                                                    | Recommended Use Case                                                                                                                                           |
| :---------------------------- | :--------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Linear IPCW**               | Assumes a linear relationship between covariates and RMST.                   | Suitable for baseline analyses where there is no strong evidence of non-linear effects or complex stratification.                                              |
| **Additive Stratified**       | Assumes the treatment adds a constant amount of survival time across strata. | Appropriate for multi-center trials where the treatment effect is expected to be uniform (e.g., a fixed increase in survival time across centers).             |
| **Multiplicative Stratified** | Assumes the treatment multiplies survival time proportionally across strata. | Preferred in multi-center trials where the treatment is expected to produce proportional gains relative to baseline survival across different centers.         |
| **Semiparametric GAM**        | Allows for non-linear covariate effects on RMST.                             | Useful when variables (e.g., age, biomarker levels) are believed to have complex, non-linear associations with the outcome.                                    |
| **Dependent Censoring**       | Accounts for dependent censoring or competing risks.                         | Recommended for studies involving competing events, such as transplant studies where receiving a transplant precludes observation of pre-transplant mortality. |


# Linear IPCW Models{.tabset}

These functions implement the foundational direct linear regression model for the RMST. This model is appropriate when a linear relationship between covariates and the RMST is assumed, and when censoring is independent of the event of interest.

## Theory and Model

Based on the methods of [@tian2014], these functions model the conditional RMST as a linear function of covariates:
$$\mathbb{E}[\min(T_i, L) | Z_i] = \beta_0 + \beta_1 \text{Treatment}_i + \beta_2 \text{Covariate}_{i}$$
In this model, the expected RMST up to a pre-specified time **L** for subject *i* is modeled as a linear combination of their treatment arm and other variables $Z_i$.

To handle right-censoring, the method uses **Inverse Probability of Censoring Weighting (IPCW)**. This is achieved through the following steps:

1.  A survival curve for the **censoring distribution** is estimated using the Kaplan-Meier method (where "failure" is being censored).
2.  For each subject who experienced the primary event, a weight is calculated. This weight is the inverse of the probability of *not* being censored up to their event time.
3.  A standard weighted linear model (`lm()`) is then fitted using these weights. The model only includes subjects who experienced the event.



## Analytical Methods

The analytical functions use a formula based on the asymptotic variance of the regression coefficients to calculate power or sample size, making them extremely fast.

**Scenario**: We use the `veteran` dataset to estimate power for a trial comparing standard vs. test chemotherapy (`trt`), adjusting for the Karnofsky performance score (`karno`).

### Power Calculation - [`linear.power.analytical`](../reference/linear.power.analytical.html)

First, lets inspect the prepared `veteran` dataset.

```{r veteran_data_prep, echo=FALSE}
vet <- veteran %>%
  mutate(
    arm = ifelse(trt == 1, 0, 1),
    status = status
  )
head(vet)
```

Now, we calculate the power for a range of sample sizes using a truncation time of 9 months (270 days).

```{r veteran_power_calc}
power_results_vet <- linear.power.analytical(
  pilot_data = vet,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  linear_terms = "karno",
  sample_sizes = c(100, 150, 200, 250),
  L = 270
)
```

The results are returned as a data frame and a `ggplot` object.

```{r veteran_table_plot, echo=FALSE}

kbl(power_results_vet$results_data , caption = "Power Analysis for Veteran Dataset") %>%
 kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "center")

```

### Sample Size Calculation - [`linear.ss.analytical`](../reference/linear.ss.analytical.html)

We can also use the analytical method to find the required sample size to achieve a target power for a truncation time of one year (365 days).

```{r veteran_ss_calc}
ss_results_vet <- linear.ss.analytical(
  pilot_data = vet,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  target_power = 0.40,
  linear_terms = "karno",
  L = 365,
  n_start = 1000, n_step = 250, max_n_per_arm = 5000
)
```

```{r veteran_ss_table, echo=FALSE}

kbl(ss_results_vet$results_summary, caption = "Estimated Effect from Pilot Data") %>%
 kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "center")

ss_results_vet$results_plot +
  theme_bw(base_size = 14)

```



## Bootstrap Methods

The `.boot` suffix in function names indicates a bootstrap, or simulation-based, approach, which provides a robust, distribution-free alternative. This method repeatedly resamples from the pilot data, fits the model on each sample, and calculates power as the proportion of simulations where the treatment effect is significant. While computationally intensive, it makes fewer assumptions.

### Power and Sample Size Calculation (`.boot`)

Here is how you would call the bootstrap functions for power for the linear model. The following examples use the same `veteran` dataset, but with a smaller number of simulations for demonstration purposes. In practice, a larger number of simulations (e.g., 1,000 or more) is recommended to ensure stable results.

First we calculate the power for a range of sample sizes. The [`linear.power.boot`](../reference/linear.power.boot.html) function takes the pilot data and returns a data frame with the estimated power for each sample size.

```{r linear_boot_example}
power_boot_vet <- linear.power.boot(
  pilot_data = vet,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  linear_terms = "karno",
  sample_sizes = c(150, 200, 250),
  L = 365,
  n_sim = 200 
)
```

```{r echo=FALSE}
power_boot_vet$results_plot
```

Here is how you would call the bootstrap function for sample size calculation. We will use the function [`linear.ss.boot`](../reference/linear.ss.boot.html) to find the sample size needed to achieve a target power of 0.5, truncating at 180 days (6 months).

```{r}
ss_boot_vet <- linear.ss.boot(
  pilot_data = vet,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  target_power = 0.5,
  linear_terms = "karno",
  L = 180,
  n_sim = 500, 
  patience = 5
)
```

```{r echo=FALSE}

ss_boot_vet$results_plot +
  theme_bw(base_size = 14)
```

***

# Additive Stratified Models {.tabset}

In multi-center clinical trials, it is often necessary to stratify the analysis by a categorical variable with many levels, such as the clinical center or a discretized biomarker. Estimating a separate parameter for each stratum can be inefficient, particularly when the number of strata is large. The additive stratified model elegantly handles this situation by conditioning out the stratum-specific effects.

## Theory and Model

The semiparametric additive model for RMST, as developed by [@zhang2024], is defined as:
$$\mu_{ij} = \mu_{0j} + \beta'Z_i$$
This model assumes that the effect of the covariates $Z_i$ (which includes the treatment arm) is **additive** and constant across all strata $j$. Crucially, it allows each stratum to have its own unique baseline RMST, denoted by $\mu_{0j}$.

The estimation of the common treatment effect, $\beta$, is achieved efficiently through a **stratum-centering** approach applied to IPCW-weighted data. This method avoids the direct estimation of the numerous $\mu_{0j}$ parameters, making it computationally efficient even with a large number of strata.



## Analytical Methods

### Sample Size Calculation - [`additive.ss.analytical`](../reference/additive.ss.analytical.html)

**Scenario**: We use the `colon` dataset to design a trial stratified by the extent of local disease (`extent`), a factor with 4 levels. We want to find the sample size per stratum to achieve 80% power. Lets inspect the prepared `colon` dataset.

```{r colon_data_prep, echo=FALSE}
colon_death <- colon %>%
  filter(etype == 2) %>%
  select(time, status, rx, extent) %>%
  na.omit() %>%
  mutate(
    arm = ifelse(rx == "Obs", 0, 1),
    status = status,
    strata = factor(extent)
  )
head(colon_death)
```

Now, we run the sample size search for 80% power, truncating at 5 years (1825 days).

```{r colon_ss_calc}
ss_results_colon <- additive.ss.analytical(
  pilot_data = colon_death,
  time_var = "time", status_var = "status", arm_var = "arm", strata_var = "strata",
  target_power = 0.60,
  L = 1825,
  n_start = 100, n_step = 100, max_n_per_arm = 10000
)
```

```{r colon_ss_table, echo=FALSE}

kbl(ss_results_colon$results_summary , caption = "Estimated Effect from Pilot Data") %>%
 kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "center")
final_n_colon <- ss_results_colon$results_data$Required_N_per_Stratum
power_at_final_n_colon <- ss_results_colon$results_plot$data %>% 
  filter(N_per_Stratum == final_n_colon) %>% pull(Power)

ss_results_colon$results_plot

```

### Power Calculation - [`additive.power.analytical`](../reference/additive.power.analytical.html)

This function calculates the power for a given set of sample sizes in a stratified additive model. We will use the `colon` dataset again for this example.

```{r additive_power_calc}
power_results_colon <- additive.power.analytical(
  pilot_data = colon_death,
  time_var = "time",
  status_var = "status",
  arm_var = "arm",
  strata_var = "strata",
  sample_sizes = c(1000, 3000, 5000),
  L = 1825 # 5 years
)

```

```{r additive_power_table_plot, echo=FALSE}
kbl(power_results_colon$results_data, caption = "Power for Additive Stratified Colon Trial") %>%
 kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "center")

power_results_colon$results_plot +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "red") +
  labs(title = "Power Curve for Additive Stratified Model") +
  theme_bw(base_size = 14)
```


***

# Multiplicative Stratified Models {.tabset}

As an alternative to the additive model, the multiplicative model may be preferred if the treatment is expected to have a relative, or proportional, effect on the RMSTâ€”for example, increasing or decreasing survival time by a certain percentage.

## Theory and Model

The multiplicative model, based on the work of [@wang2019], is defined as:
$$\mu_{ij} = \mu_{0j} \exp(\beta'Z_i)$$
In this model, the covariates $Z_i$ have a **multiplicative** effect on the baseline stratum-specific RMST, $\mu_{0j}$. This structure is equivalent to a linear model on the log-RMST.

While the formal estimation of $\beta$ requires a complex iterative solver, this package uses a practical and computationally efficient approximation. It fits a weighted log-linear model (`lm(log(Y_rmst) ~ ...)`) to the data, which provides robust estimates for the effect size (the log-RMST ratio) and its variance.



## Analytical Methods

### Power Calculation - [`MS.power.analytical`](../reference/MS.power.analytical.html)

This function calculates the power for various sample sizes using the analytical method for the multiplicative stratified model.

```{r ms_power_analytical_example}
power_ms_analytical <- MS.power.analytical(
   pilot_data = colon_death,
   time_var = "time", status_var = "status", arm_var = "arm", strata_var = "strata",
   sample_sizes = c(300, 400, 500),
   L = 1825
)
```

```{r echo=FALSE}

kbl(power_ms_analytical$results_data, caption = "Power for Multiplicative Stratified Model") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "center")
```

### Sample Size Calculation - [`MS.ss.analytical`](../reference/MS.ss.analytical.html)

The following example demonstrates the sample size calculation using the same model.

```{r ms_ss_analytical_example}
ms_ss_results_colon <- MS.ss.analytical(
   pilot_data = colon_death, time_var = "time", status_var = "status", arm_var = "arm", strata_var = "strata",
   target_power = 0.6,L = 1825)
```

```{r echo=FALSE}

kbl(ms_ss_results_colon$results_summary, caption = "Sample Size for Multiplicative Stratified Model") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "center")

ms_ss_results_colon$results_plot +
   theme_bw(base_size = 14)
```



## Bootstrap Methods

The bootstrap approach provides a more robust, simulation-based analysis for the multiplicative model.

### Power Calculation - [`MS.power.boot`](../reference/MS.power.boot.html)

The following code demonstrates how to call the `MS.power.boot` function.

```{r ms_power_boot_example}
power_ms_boot <- MS.power.boot(
   pilot_data = colon_death,
   time_var = "time",
   status_var = "status",
   arm_var = "arm",
   strata_var = "strata",
   sample_sizes = c(100, 300, 500),
   L = 1825,
   n_sim = 100, 
   parallel.cores = 10 
)
```

```{r echo=FALSE}
kbl(power_ms_boot$results_summary, caption = "Power for Multiplicative Stratified Model (Bootstrap)") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "center")
power_ms_boot$results_plot 
```

### Sample Size Calculation - [`MS.ss.boot`](../reference/MS.ss.boot.html)

Similarly, the sample size can be calculated using bootstrap simulation.

```{r ms_ss_boot_example}
ss_ms_boot <- MS.ss.boot(
   pilot_data = colon_death,
   time_var = "time",
   status_var = "status",
   arm_var = "arm",
   strata_var = "strata", 
   target_power = 0.5,
   L = 1825,
   n_sim = 100,
   n_start = 100,
   n_step = 50,
   patience = 4,
   parallel.cores = 10
)
```

```{r echo=FALSE}

kbl(ss_ms_boot$results_summary, caption = "Sample Size for Multiplicative Stratified Model (Bootstrap)") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "center")
```

***

# Semiparametric GAM Models {.tabset}

When a covariate is expected to have a non-linear effect on the outcome (for example, the effect of age or a biomarker), standard linear models may be misspecified. Generalized Additive Models (GAMs) provide a flexible solution by modeling such relationships with smooth functions.

## Theory and Model

These functions use a bootstrap simulation approach combined with a GAM. The method involves two main steps:

1.  **Jackknife Pseudo-Observations**: The time-to-event outcome is first converted into **jackknife pseudo-observations** for the RMST. This technique, explored in recent statistical literature for RMST estimation [@perdry2024], creates a continuous, uncensored variable that represents each subject's contribution to the RMST. This makes the outcome suitable for use in a standard regression framework.

2.  **GAM Fitting**: A GAM is then fitted to these pseudo-observations. The model has the form:
    $$\mathbb{E}[\text{pseudo}_i] = \beta_0 + \beta_1 \cdot \text{Treatment}_i + \sum_{k=1}^{q} f_k(\text{Covariate}_{ik})$$
    Here, $f_k()$ are the non-linear **smooth functions** (splines) that the GAM estimates from the data.

### Power Calculation Formula (`GAM.power.boot`)

Because this is a bootstrap method, power is not calculated from a direct formula but is instead estimated empirically from the simulations:
$$\text{Power} = \frac{1}{B} \sum_{b=1}^{B} \mathbb{I}(p_b < \alpha)$$
Where:

* $B$ is the total number of bootstrap simulations (`n_sim`).

* $p_b$ is the p-value for the treatment effect in the $b$-th simulation.

* $\mathbb{I}(\cdot)$ is the indicator function, which is 1 if the condition is true and 0 otherwise.



## Bootstrap Methods

### Power Calculation - [`GAM.power.boot`](../reference/GAM.power.boot.html)

**Scenario**: We use the `gbsg` (German Breast Cancer Study Group) dataset, suspecting that the progesterone receptor count (`pgr`) has a non-linear effect on recurrence-free survival. Here is a look at the prepared `gbsg` data.

```{r gbsg_data_prep, echo=FALSE}
gbsg_prepared <- gbsg %>%
   mutate(
      arm = ifelse(hormon == "no", 0, 1)
   )
head(gbsg_prepared)
```

The following code shows how to calculate power.

```{r gbsg_power_calc}
power_gam <- GAM.power.boot(
   pilot_data = gbsg_prepared,
   time_var = "rfstime",
   status_var = "status",
   arm_var = "arm",
   smooth_terms = "pgr", # Model pgr with a smooth term
   sample_sizes = c(50, 200, 400),
   L = 2825, # 5 years
   n_sim = 500,
   parallel.cores = 10
)

print(power_gam$results_plot)
```

### Sample Size Calculation - [`GAM.ss.boot`](../reference/GAM.ss.boot.html)

**Scenario**: We want to find the sample size needed to achieve 80% power for detecting an effect of `pgr` on recurrence-free survival.

```{r}
ss_gam <- GAM.ss.boot(
   pilot_data = gbsg_prepared,
   time_var = "rfstime",
   status_var = "status",
   arm_var = "arm",
   target_power = 0.95,
   L = 182, 
   n_sim = 500, 
   patience = 5,
   parallel.cores = 10
)
```

```{r echo=FALSE}
ss_gam$results_plot +
   theme_bw(base_size = 14)
```


***

# Dependent Censoring Models

In some studies, particularly observational or registry studies, censoring may not be independent of the event of interest. A classic example is in transplant medicine, where receiving an organ transplant removes a patient from being at risk of pre-transplant death. This is a form of **competing risk**, which can also be viewed as dependent censoring.

## Theory and Model

The methods from [@wang2018] address this by extending the IPCW framework. Instead of a single model for the overall censoring distribution, **cause-specific PH models** are fitted for each of the $K$ sources of censoring (e.g., one model for administrative censoring, another for the competing event).

The final weight for a subject is then a product of the weights derived from all censoring causes, calculated as:
$$W_i = \exp\left(\sum_{k=1}^{K} \hat{\Lambda}_{k}(Y_i)\right)$$
where $\hat{\Lambda}_{k}$ is the estimated cumulative hazard for censoring cause `k`, and $Y_i = \min(T_i, L)$ is the truncated event time. The final analysis is a weighted linear regression on the RMST.



### Power Calculation Formula (`DC.power.analytical`)

Power is calculated analytically using the standard formula:
$$\text{Power} = \Phi\left( \frac{|\beta_{\text{effect}}|}{\sigma_N} - z_{1-\alpha/2} \right)$$
The key difference in this model is that the variance, $\sigma_N^2$, is derived from a robust sandwich estimator that properly accounts for the multiple weighting components from the different cause-specific hazard models.

## Analytical Methods

 We will use the `mgus2` dataset for this scenario.

```{r mgus2_data_prep, echo=FALSE}
mgus_prepared <- mgus2 %>%
   mutate(
      event_primary = ifelse(pstat == 1, 1, 0),
      event_dependent = ifelse(pstat == 0 & death > 0, 1, 0),
      arm = ifelse(sex == "M", 1, 0)
   ) %>%
   rename(time = futime)
head(mgus_prepared)
```

### Power Calculation - [`DC.power.analytical`](../reference/DC.power.analytical.html)

This function calculates power for a study with dependent censoring (competing risks) for a given set of sample sizes.

```{r dc_power_calc}
dc_power_results <- DC.power.analytical(
   pilot_data = mgus_prepared,
   time_var = "time",
   status_var = "event_primary",
   arm_var = "arm",
   dep_cens_status_var = "event_dependent",
   sample_sizes = c(100, 250, 500),
   linear_terms = "age",
   L = 120 # 10 years
)
```

```{r echo=FALSE}
kbl(dc_power_results$results_summary, caption = "Power Analysis for MGUS Progression Study") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "center")

dc_power_results$results_plot
```

### Sample Size Calculation - [`DC.ss.analytical`](../reference/DC.ss.analytical.html)

Now, find the sample size needed for 80% power, truncating at 10 years (120 months).

```{r mgus2_ss_calc}
ss_dc_mgus <- DC.ss.analytical(
   pilot_data = mgus_prepared,
   time_var = "time",
   status_var = "event_primary",
   arm_var = "arm",
   dep_cens_status_var = "event_dependent",
   target_power = 0.80,
   linear_terms = "age",
   L = 120, # 10 years
   n_start = 100, n_step = 50, max_n_per_arm = 5000
)

```

```{r mgus2_table, echo=FALSE}

kbl(ss_dc_mgus$results_summary, caption = "Estimated Effect from Pilot Data") %>%
  kable_styling(bootstrap_options = "striped", full_width = FALSE, position = "center")

ss_dc_mgus$results_plot +
   theme_bw(base_size = 14)

```

# Interactive Shiny Application

For users who prefer a graphical interface, `RMSTSS` provides an interactive Shiny web application that offers a point-and-click interface to all the models and methods described in this vignette.

### Accessing the Application

There are two ways to access the application:

1.  **Live Web Version (Recommended)**: Access the application directly in your browser without any installation.

    -   [Launch Web Application](https://arnab96.shinyapps.io/uthsc-app/)

2.  **Run Locally from the R Package**: If you have installed the `RMSTSS-Package`, you can run the application on your own machine with the following command:

```{r, eval=FALSE}
RMSTSS::run_app()
```

### App Features

-   **Interactive Data Upload**: Upload your pilot dataset in `.csv` format.
-   **Visual Column Mapping**: Visually map the columns in your data to the required variables for the analysis (e.g., time, status, treatment arm).
-   **Full Model Selection**: Choose the desired RMST model, calculation method (analytical or bootstrap), and set all relevant parameters through user-friendly controls.
-   **Rich Visualization**: Execute the analysis and view the results, including survival plots, power curves, and summary tables, all within the application.
-   **Downloadable Reports**: Generate and download a complete, publication-ready analysis report in PDF format.

# Conclusion

The `RMSTSS` package provides a powerful and flexible suite of tools for designing and analyzing clinical trials using the Restricted Mean Survival Time.

## Advantages and Disadvantages

-   **Advantages**: The package implements a wide range of modern statistical methods, allowing users to handle complex scenarios like stratification, non-linear effects, and competing risks. The provision of both fast analytical methods and robust bootstrap methods gives users a choice between speed and distributional flexibility.
-   **Disadvantages**: The primary limitation is the reliance on representative pilot data. The accuracy of any power or sample size calculation is contingent on the effect sizes and variance structures estimated from the pilot dataset. Furthermore, the bootstrap-based methods can be computationally intensive and may require access to parallel computing resources for timely results.

## Future Work

Future development could involve extending the bootstrap approach to the dependent censoring models and incorporating more advanced model diagnostic tools to help users assess the adequacy of their chosen model based on the pilot data.

# References


